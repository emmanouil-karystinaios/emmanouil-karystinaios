<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><meta name=author content="Emmanouil Karystinaios"><meta name=description content="Visualizing Graph Neural Network Explanations for music."><link rel=alternate hreflang=en-us href=https://emmanouil-karystinaios.github.io/post/smug/><meta name=theme-color content="#1565c0"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.832f4349361bf479dece6e8aacc6bfa5.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu4c3aa08d28a737b1b7fdd38226539d61_369298_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu4c3aa08d28a737b1b7fdd38226539d61_369298_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://emmanouil-karystinaios.github.io/post/smug/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="og:site_name" content="Emmanouil Karystinaios"><meta property="og:url" content="https://emmanouil-karystinaios.github.io/post/smug/"><meta property="og:title" content="From Notes to Insights - Visualizing Graph Neural Network Explanations with SMUG-Explain | Emmanouil Karystinaios"><meta property="og:description" content="Visualizing Graph Neural Network Explanations for music."><meta property="og:image" content="https://emmanouil-karystinaios.github.io/post/smug/featured.png"><meta property="twitter:image" content="https://emmanouil-karystinaios.github.io/post/smug/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2024-06-27T00:00:00+00:00"><meta property="article:modified_time" content="2024-06-27T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://emmanouil-karystinaios.github.io/post/smug/"},"headline":"From Notes to Insights - Visualizing Graph Neural Network Explanations with SMUG-Explain","image":["https://emmanouil-karystinaios.github.io/post/smug/featured.png"],"datePublished":"2024-06-27T00:00:00Z","dateModified":"2024-06-27T00:00:00Z","author":{"@type":"Person","name":"Emmanouil Karystinaios"},"publisher":{"@type":"Organization","name":"Emmanouil Karystinaios","logo":{"@type":"ImageObject","url":"https://emmanouil-karystinaios.github.io/media/icon_hu4c3aa08d28a737b1b7fdd38226539d61_369298_192x192_fill_lanczos_center_3.png"}},"description":"Visualizing Graph Neural Network Explanations for music."}</script><title>From Notes to Insights - Visualizing Graph Neural Network Explanations with SMUG-Explain | Emmanouil Karystinaios</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=1a56b53fc811de3277579778f9503ea5><script src=/js/wowchemy-init.min.2ed908358299dd7ab553faae685c746c.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Emmanouil Karystinaios</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Emmanouil Karystinaios</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/publication/><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>From Notes to Insights - Visualizing Graph Neural Network Explanations with SMUG-Explain</h1><p class=page-subtitle>Visualizing Graph Neural Network Explanations with SMUG-Explain</p><div class=article-metadata><div><span>Emmanouil Karystinaios</span></div><span class=article-date>Jun 27, 2024</span>
<span class=middot-divider></span>
<span class=article-reading-time>7 min read</span>
<span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/graph-neural-networks/>Graph Neural Networks</a>, <a href=/category/cadence/>Cadence</a>, <a href=/category/interpretability/>Interpretability</a></span></div></div><div class="article-header container featured-image-wrapper mt-4 mb-4" style=max-width:825px;max-height:616px><div style=position:relative><img src=/post/smug/featured_hu946ab470ce8d8e6d9a3891920ffdbdac_111429_1200x2500_fit_q75_h2_lanczos_3.webp width=825 height=616 alt class=featured-image>
<span class=article-header-caption>SMUG-Explain: Visualizing Graph Neural Network Explanations for Music Scores</span></div></div><div class=article-container><div class=article-style><p>Graph Neural Networks (GNNs) are making waves in the world of Music Information Research (MIR). From predicting cadences to generating expressive performances, these networks are unlocking new potentials in understanding and processing musical scores. But there’s a catch — their complex, “black-box” nature makes them hard to interpret. That’s where SMUG-Explain comes in. This innovative framework is designed to generate and visualize explanations for GNNs applied to musical scores. Let’s dive into how SMUG-Explain works, its application in cadence detection, and its potential to bring AI and musicology closer together.</p><h2 id=the-challenge-understanding-gnns-in-music>The Challenge: Understanding GNNs in Music</h2><p>GNNs are fantastic at capturing intricate relationships in graph-structured data, which is perfect for tasks like cadence detection and voice separation in music. However, they’re notoriously difficult to interpret. For musicians and researchers, this opacity can be a big problem. Imagine having a super-smart assistant who helps you analyze music but never explains why it made certain decisions. Frustrating, right?</p><p>Enter SMUG-Explain, or Score MUsic Graph Explain. This is a framework for interpreting GNNs applied to music but it also integrates these explanations directly into the musical scores. By visualizing how each note and its features contribute to the model’s predictions, SMUG-Explain makes GNNs more transparent and understandable.</p><h2 id=how-does-smug-explain-work>How Does SMUG-Explain Work?</h2><h3 id=graph-based-representation-of-musical-scores>Graph-Based Representation of Musical Scores</h3><p>SMUG-Explain transforms a musical score into a graph where notes are vertices, and edges represent their temporal relationships. It uses four types of edges:</p><ul><li>Onset edges: Connect notes that start together.</li><li>Consecutive edges: Link notes where one ends as the next begins.</li><li>During edges: Connect notes that occur within the duration of another note.</li><li>Rest edges: Connect notes across rests.</li></ul><p><figure id=figure-in-this-example-we-view-the-score-graph-on-an-excerpt-of-a-perfect-authentic-cadence-pac-with-harmonic-annotations-written-in-roman-numerals><div class="d-flex justify-content-center"><div class=w-100><img src=./figs/Example_Score.png alt="Score Graph Example" loading=lazy data-zoomable></div></div><figcaption>In this example, we view the score graph on an excerpt of a Perfect Authentic Cadence (PAC) with harmonic annotations written in Roman numerals.</figcaption></figure></p><h3 id=explanation-techniques>Explanation Techniques</h3><p>SMUG-Explain employs several post-hoc, gradient-based explanation methods such as Saliency, Integrated Gradients, Deconvolution, and Guided Backpropagation. These techniques evaluate the importance of each note and its features in predicting specific musical events, such as cadences. Additionally, these methods allow us to derive attribution weights for every edge in the input graph. By selecting the top-k most important edges, we can construct an explanation subgraph that highlights the critical components influencing the model’s predictions.</p><h3 id=evaluation-of-explanations>Evaluation of Explanations</h3><p>The quality of an explanation is assessed using fidelity metrics. For each explanation subgraph, the underlying cadence prediction model is run on the subgraph alone or on the input graph without the explanation subgraph. If the correct cadence label can be predicted using only the explanation subgraph, the explanation is deemed sufficient. Conversely, if the label changes when the input graph is used without the explanation subgraph, the explanation is considered necessary. An explanation that is both necessary and sufficient achieves a perfect fidelity score, indicating it provides a comprehensive and accurate insight into the model’s decision-making process.</p><h2 id=interactive-visualization>Interactive Visualization</h2><p>The framework features an interactive web interface built with the Verovio music engraving library. Users can click on individual notes to see the subgraphs that most contribute to the model’s predictions and the feature importance of each note. This interface not only makes the explanations accessible but also aligns them with traditional music notation, making it easier for musicians and researchers to understand.</p><h2 id=real-world-applications-mozart-to-chopin>Real-World Applications: Mozart to Chopin</h2><h3 id=mozarts-piano-sonata-k280>Mozart’s Piano Sonata K280</h3><p>In an excerpt from Mozart’s Piano Sonata K280, the underlying GNN analysis model accurately identified a perfect authentic cadence. Using the SMUG-Explain framework we can see that the explanations outline the descending melodic line and the bass arpeggiation leading to the cadence, aligning closely with traditional harmonic analysis. This example highlights the framework’s potential to support musicological research.</p><p><figure id=figure-potential-reduction-process-of-smug-explain-pac-indicates-the-predicted-arrival-point-of-the-cadence><div class="d-flex justify-content-center"><div class=w-100><img src=./figs/smug.gif alt="Mozart&amp;rsquo;s Piano Sonata K280" loading=lazy data-zoomable></div></div><figcaption>Potential reduction process of Smug-Explain. PAC indicates the predicted arrival point of the cadence.</figcaption></figure></p><p>When we isolate the explanation and apply a reduction process, retaining only the subgraph involved in the explanation, we are left with the essential structure of a textbook harmonic Perfect Authentic Cadence (PAC). This streamlined subgraph highlights the critical notes and relationships that define the PAC. While this process shows how SMUG-Explain can break down complex musical structures into their core elements, due to the complexity of musical reduction it isn’t a built-in feature just yet.</p><h3 id=chopins-nocturne-in-c-minor>Chopin’s Nocturne in C Minor</h3><p>In Chopin’s Nocturne, SMUG-Explain correctly identified a complex cadence despite unconventional voice leading. The explanation subgraph included notes from earlier measures, indicating the model’s consideration of long-range musical dependencies, much like human musicological analysis. Notice how the explanation highlights the first chord in the first measure probably as an indication of the key.</p><p><figure id=figure-explanation-of-the-cadence-detection-in-chopins-nocturne-in-c-minor><div class="d-flex justify-content-center"><div class=w-100><img src=./figs/choping_smug.webp alt="Chopin&amp;rsquo;s Nocturne in C Minor" loading=lazy data-zoomable></div></div><figcaption>Explanation of the cadence detection in Chopin&rsquo;s Nocturne in C Minor.</figcaption></figure></p><h2 id=future-directions>Future Directions</h2><p>SMUG-Explain is paving the way for making GNNs in music more interpretable and user-friendly. Future work will focus on developing new explanation techniques tailored to musical data, enhancing user-based evaluations, and making the framework more accessible through online platforms.
Limitations of SMUG-Explain</p><p>While SMUG-Explain represents a significant step forward in making Graph Neural Networks (GNNs) more interpretable in the context of musical scores, it is not without its limitations. Understanding these constraints is crucial for setting realistic expectations and guiding future improvements. Here are some key limitations of the SMUG-Explain framework:</p><h4 id=1-model-dependence>1. Model Dependence</h4><p>An important limitation of SMUG-Explain lies in its dependence on the underlying GNN model used for cadence detection. Since SMUG-Explain employs post-hoc explanation methods, the accuracy and quality of its explanations are directly tied to the performance of the cadence detection model.</p><p>The explanations generated by SMUG-Explain are only as good as the predictions made by the cadence detection model. If the underlying model has poor accuracy or fails to capture essential musical elements, the explanations provided will reflect these shortcomings. This means that any inaccuracies or biases in the model will be present in the explanations, potentially leading to misleading insights.</p><p>The performance of the cadence detection model depends heavily on the quality and comprehensiveness of the training data. If the training dataset lacks diversity or contains errors, the model’s ability to generalize to new pieces will be compromised. Consequently, the explanations generated for these predictions may not be reliable or musically meaningful.</p><p>Some musical compositions, especially those with complex structures and unconventional harmonies, might pose significant challenges for the cadence detection model. If the model struggles with these complexities, the explanations provided by SMUG-Explain may fail to accurately represent the underlying musical relationships, leading to incomplete or incorrect interpretations.</p><h4 id=2-complexity-of-graph-constructions>2. Complexity of Graph Constructions</h4><p>Creating accurate graph representations of musical scores is inherently complex. While SMUG-Explain uses onset, consecutive, during, and rest edges to model relationships between notes, this approach might not capture all the nuances of a musical piece. Elements like dynamics, articulations, and tempo changes are not explicitly represented in the current graph model, potentially overlooking important musical information.</p><h4 id=3-user-experience-and-accessibility>3. User Experience and Accessibility</h4><p>Although the interactive interface of SMUG-Explain makes it accessible to users, it still requires a certain level of technical proficiency to operate effectively. Users need to be familiar with both music theory and the technical aspects of GNNs to fully leverage the framework. Additionally, the current implementation relies on local deployment, which might be a barrier for widespread use. An online, server-based version could enhance accessibility but has yet to be developed.</p><h4 id=4-interpretation-of-explanations>4. Interpretation of Explanations</h4><p>While SMUG-Explain provides visual explanations that align with traditional music notation, interpreting these explanations still requires a deep understanding of music theory and machine learning. The explanations might not be immediately intuitive to all users, particularly those without a background in musicology or computational music research.</p><h2 id=conclusion>Conclusion</h2><p>SMUG-Explain bridges the gap between the sophisticated world of GNNs and the nuanced demands of musicology. By providing clear, interactive explanations directly within the context of musical scores, it empowers users to understand and trust the decisions of AI models, paving the way for more effective and insightful musical analyses.</p><p>If you’re intrigued and want to explore SMUG-Explain further, check out the code on <a href=https://github.com/manoskary/SMUG-Explain target=_blank rel=noopener>GitHub</a> or <a href=https://arxiv.org/abs/2405.09241 target=_blank rel=noopener>read the paper</a>. Dive in and discover how AI can illuminate the intricate beauty of musical compositions.</p><h2 id=acknowledgments>Acknowledgments</h2><p>I extend my gratitude to Francesco Foscarin, co-author of the original paper, for his invaluable assistance with the writing of this blog post and for providing some of the graphics.</p></div><div class=article-tags><a class="badge badge-light" href=/tag/academic/>Academic</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://emmanouil-karystinaios.github.io/post/smug/&text=From%20Notes%20to%20Insights%20-%20Visualizing%20Graph%20Neural%20Network%20Explanations%20with%20SMUG-Explain" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://emmanouil-karystinaios.github.io/post/smug/&t=From%20Notes%20to%20Insights%20-%20Visualizing%20Graph%20Neural%20Network%20Explanations%20with%20SMUG-Explain" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=From%20Notes%20to%20Insights%20-%20Visualizing%20Graph%20Neural%20Network%20Explanations%20with%20SMUG-Explain&body=https://emmanouil-karystinaios.github.io/post/smug/" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://emmanouil-karystinaios.github.io/post/smug/&title=From%20Notes%20to%20Insights%20-%20Visualizing%20Graph%20Neural%20Network%20Explanations%20with%20SMUG-Explain" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=From%20Notes%20to%20Insights%20-%20Visualizing%20Graph%20Neural%20Network%20Explanations%20with%20SMUG-Explain%20https://emmanouil-karystinaios.github.io/post/smug/" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://emmanouil-karystinaios.github.io/post/smug/&title=From%20Notes%20to%20Insights%20-%20Visualizing%20Graph%20Neural%20Network%20Explanations%20with%20SMUG-Explain" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://emmanouil-karystinaios.github.io/><img class="avatar mr-3 avatar-circle" src=/authors/admin/avatar_hu20b1ad684682ccdf4e638b33c3ec6d54_148841_270x270_fill_q75_lanczos_center.jpg alt="Emmanouil Karystinaios"></a><div class=media-body><h5 class=card-title><a href=https://emmanouil-karystinaios.github.io/>Emmanouil Karystinaios</a></h5><h6 class=card-subtitle>Postdoctoral Researcher in Artificial Intelligence</h6><p class=card-text>My research interests include Music Information Retrieval and Graph Neural Networks</p><ul class=network-icon aria-hidden=true><li><a href=/#contact><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?hl=en&user=bQRK3eYAAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/manoskary target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/manos-karistineos/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=/media/resume.pdf><i class="ai ai-cv"></i></a></li></ul></div></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© {2022} Emmanouil Karystinaios.</p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.fab8b449b814cc9f95b22fcf2e45f05b.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js type=module></script>
<script src=/en/js/wowchemy.min.d14f720598b8ad98ae8105a0a502bab6.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>